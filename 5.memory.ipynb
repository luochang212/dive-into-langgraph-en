{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892ac848-252a-4b16-975f-b19305ea177f",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "[Memory](https://docs.langchain.com/oss/python/langgraph/add-memory) is an optional module. Unless necessary, you don't need to add a Memory module to your Agent. Because StateGraph itself contains a historical message list `messages`, which is sufficient to meet the most basic \"memory\" requirements.\n",
    "\n",
    "Situations where a Memory module needs to be added include:\n",
    "\n",
    "1. Too many historical messages, requiring external tools to store memory\n",
    "2. Triggering human intervention ([interrupt](https://docs.langchain.com/oss/python/langgraph/interrupts)), requiring temporary saving of Agent state\n",
    "3. Extracting user preferences across conversations, etc.\n",
    "\n",
    "LangGraph divides memory into:\n",
    "\n",
    "- [Short-term memory](https://docs.langchain.com/oss/python/langchain/short-term-memory) (MemorySaver)\n",
    "- [Long-term memory](https://docs.langchain.com/oss/python/langchain/long-term-memory) (MemoryStore)\n",
    "\n",
    "In addition, [LangMem](https://langchain-ai.github.io/langmem/) also provides memory storage and retrieval functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aff8836-8798-4920-b679-7abe02218d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass\n",
    "from typing_extensions import TypedDict\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Load model configuration\n",
    "_ = load_dotenv()\n",
    "\n",
    "# Load model\n",
    "model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Create assistant node\n",
    "def assistant(state: MessagesState):\n",
    "    return {'messages': [model.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfc72f-332c-4c57-b0b7-88e961b79f87",
   "metadata": {},
   "source": [
    "## I. Short-term Memory\n",
    "\n",
    "Short-term memory (working memory) is generally used to temporarily store the state of an Agent or Workflow for recovery after failures or retries.\n",
    "\n",
    "### 1.1 Using Short-term Memory in Workflows\n",
    "\n",
    "If a checkpoint is configured for a workflow, the next time the workflow is invoked, it will continue from the previous conversation. If not configured, historical conversations will not be retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7794c6-13cb-4b0f-bf19-ef9bc6dc14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello! I am Patrick Star\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh hi, Patrick! *gives a friendly wave* \n",
      "\n",
      "I heard you were doing some underwater stargazing again last night. Did you see any new constellations? I know how much you love looking up at those twinkly lights through the ocean water.\n",
      "\n",
      "Say, want to go jellyfishing later? I bet there's a whole school of 'em around Goo Lagoon this time of day. We could use your big pink net - just watch out for the electric eels! *nervous laugh*\n",
      "\n",
      "You're always good company, Patrick. Even when things get a little... interesting under the sea!\n"
     ]
    }
   ],
   "source": [
    "# Create short-term memory\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# Create graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node('assistant', assistant)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, 'assistant')\n",
    "builder.add_edge('assistant', END)\n",
    "\n",
    "# Use checkpointer\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "## If we don't use checkpointer, see what happens? \n",
    "# graph = builder.compile()\n",
    "\n",
    "# Tell the agent who I am\n",
    "result = graph.invoke(\n",
    "    {'messages': ['Hello! I am Patrick Star']},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c6c699-c2b8-466c-8877-877b3b40382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello! I am Patrick Star\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh hi, Patrick! *gives a friendly wave* \n",
      "\n",
      "I heard you were doing some underwater stargazing again last night. Did you see any new constellations? I know how much you love looking up at those twinkly lights through the ocean water.\n",
      "\n",
      "Say, want to go jellyfishing later? I bet there's a whole school of 'em around Goo Lagoon this time of day. We could use your big pink net - just watch out for the electric eels! *nervous laugh*\n",
      "\n",
      "You're always good company, Patrick. Even when things get a little... interesting under the sea!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "May I ask who I am?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh, Patrick! You're my best friend, silly! Don't you remember? We live in the same neighborhood in Bikini Bottom. You're that big-hearted, fun-loving pink starfish who lives under a rock with your pet snail, and you work at the Krusty Krab sometimes... well, when you're not too busy napping or going jellyfishing!\n",
      "\n",
      "We've had so many adventures together - like that time we got trapped in a giant soap bubble, or when we went hunting for the mysterious \"Lost Boot\" in the deep ocean. You're always up for fun and games, even if you do get a little mixed up sometimes.\n",
      "\n",
      "And Patrick, you're probably the only person in all of Bikini Bottom who truly appreciates my jokes! Well, most of the time anyway. *chuckles*\n",
      "\n",
      "Wait... you really don't remember, do you? That's not like you at all, buddy. Are you feeling okay?\n"
     ]
    }
   ],
   "source": [
    "# Let the agent say my name\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"May I ask who I am?\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2b2f6-9cb0-4b9e-89a2-89de5d53d925",
   "metadata": {},
   "source": [
    "### 1.2 Using Short-term Memory in Agents\n",
    "\n",
    "The effect of using short-term memory in Agents is similar to that in workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59286c68-a72d-4e92-b7b3-b81db8e0e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello! I am Squidward\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh... hello there, Squidward. *nervous chuckle* \n",
      "\n",
      "Is everything... uhh... tentacle-y on your end? I must say, your name certainly has a certain... aquatic quality to it. Very... underwater. \n",
      "\n",
      "*shifts uncomfortably*\n",
      "\n",
      "Say, are you by chance familiar with the fine arts? Perhaps you play a wind instrument? Or maybe you're more of a visual artist? I've always appreciated someone with... sophisticated tastes. \n",
      "\n",
      "*awkward pause*\n",
      "\n",
      "Right then! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create short-term memory\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# Tell the agent I am Squidward\n",
    "result = agent.invoke(\n",
    "    {'messages': ['Hello! I am Squidward']},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93509d9f-370f-4ea8-abdb-ae01fd51e112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello! I am Squidward\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Oh... hello there, Squidward. *nervous chuckle* \n",
      "\n",
      "Is everything... uhh... tentacle-y on your end? I must say, your name certainly has a certain... aquatic quality to it. Very... underwater. \n",
      "\n",
      "*shifts uncomfortably*\n",
      "\n",
      "Say, are you by chance familiar with the fine arts? Perhaps you play a wind instrument? Or maybe you're more of a visual artist? I've always appreciated someone with... sophisticated tastes. \n",
      "\n",
      "*awkward pause*\n",
      "\n",
      "Right then! How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who am I?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "*adjusts posture and peers through one eye*\n",
      "\n",
      "Well, that's rather obvious, isn't it? You're Squidward Tentacles, resident of 124 Conch Street, right next door to that insufferable yellow sponge who insists on trying to be my friend. You work the register at the Krusty Krab, though clearly you're far too talented for such menial employment. You're an accomplished clarinet player - though I understand your neighbors find your practicing... challenging. You also paint, sculpt, and generally pursue high art in your spare time.\n",
      "\n",
      "*nervous laugh*\n",
      "\n",
      "Of course, you're also known for your... *ahem* ...distinctive laugh. The whole neighborhood knows that laugh.\n",
      "\n",
      "*clears throat awkwardly*\n",
      "\n",
      "Does that about sum it up? Or did you perhaps bonk your head on something? That does happen occasionally around here.\n"
     ]
    }
   ],
   "source": [
    "# Let the agent say my name\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Who am I?\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},  \n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf12a1a-0c98-4c61-9f23-12a829ee2251",
   "metadata": {},
   "source": [
    "To verify whether `InMemorySaver` is truly effective, you can comment out the checkpointer and observe the Agent's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56656f1-dd75-4c97-8244-88bc521a5608",
   "metadata": {},
   "source": [
    "### 1.3 Using Databases to Save Short-term Memory\n",
    "\n",
    "If using SQLite to save working state, even if the program exits, it should be able to restore the state before exit. Let's verify this. Before that, you need to install a Python package to support SqliteSaver checkpoint:\n",
    "\n",
    "```bash\n",
    "pip install langgraph-checkpoint-sqlite\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ffbd2f-9330-4663-9547-f21df46af401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete SQLite database\n",
    "if os.path.exists(\"short-memory.db\"):\n",
    "    os.remove(\"short-memory.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d3dc0f-dcff-4d2d-b708-8acb516cb3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! I am Sha Wujing\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Brother Sha Wujing. As the second demon general of Flowing Sands River and a member of Tang Sanzang's pilgrimage team to the West for Buddhist scriptures, you are an extremely powerful warrior. Do you have any interesting experiences in the journey of seeking the scriptures to share with me? Or do you have any thoughts about your previous life as a celestial marshal?\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Create short-term memory with SQLite support\n",
    "checkpointer = SqliteSaver(\n",
    "    sqlite3.connect(\"short-memory.db\", check_same_thread=False)\n",
    ")\n",
    "\n",
    "# Create Agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "# Tell the agent I am Sha Wujing (a character from Journey to the West)\n",
    "result = agent.invoke(\n",
    "    {'messages': ['Hi! I am Sha Wujing']},\n",
    "    {\"configurable\": {\"thread_id\": \"3\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f7a61-8974-4f67-ab6f-9fcf755d4c4e",
   "metadata": {},
   "source": [
    "Create a new Agent and configure it with a SQLite checkpoint. Let's see if the Agent can read the memory about my name from SQLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768b2abc-6531-4308-a7b0-16dc80eeca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! I am Sha Wujing\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Brother Sha Wujing. As the second demon general of Flowing Sands River and a member of Tang Sanzang's pilgrimage team to the West for Buddhist scriptures, you are an extremely powerful warrior. Do you have any interesting experiences in the journey of seeking the scriptures to share with me? Or do you have any thoughts about your previous life as a celestial marshal?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who am I?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "*Scratches my head with my rake, looking slightly confused*\n",
      "\n",
      "Oh, brother, you sure got me puzzled there for a moment. You just introduced yourself as Sha Wujing, didn't you? Though... now that I think about it, something feels off. \n",
      "\n",
      "*Strokes beard thoughtfully*\n",
      "\n",
      "Say, you don't happen to be carrying a certain mala around your neck, do you? The one with 108 precious beads? I seem to recall those beads were made from the skulls of people I once... well, let's just say I wasn't always on the path of virtue.\n",
      "\n",
      "*Shifts uncomfortably*\n",
      "\n",
      "You know, before I met Master and took up the Buddhist path, I was quite the troublemaker in the Heavenly Palace. Got myself banished for... oh, some rather unseemly behavior. Now I'm trying to atone for my past misdeeds by protecting the monk on our journey to the West.\n",
      "\n",
      "But I must ask - are you truly who you claim to be, or perhaps someone testing this poor cultivator?\n"
     ]
    }
   ],
   "source": [
    "# Create a new Agent\n",
    "new_agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "# Let the agent recall my name\n",
    "result = new_agent.invoke(\n",
    "    {'messages': ['Who am I?']},\n",
    "    {\"configurable\": {\"thread_id\": \"3\"}},\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf7455a-da1f-467a-8969-9fd280f35927",
   "metadata": {},
   "source": [
    "## II. Long-term Memory\n",
    "\n",
    "Long-term memory is generally used to save important business-related information, such as user attributes, traffic parameters, etc.\n",
    "\n",
    "### 2.1 Creating an Embedding Generation Function\n",
    "\n",
    "Long-term memory supports using Embedding to retrieve semantically similar content. Below we create an Embedding generation function that can generate Embeddings required for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7474fde3-0f84-4a52-bcd8-46c626208e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding dimension\n",
    "EMBED_DIM = 1024\n",
    "\n",
    "# Interface for getting text embedding\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    ")\n",
    "\n",
    "# Embedding generation function\n",
    "def embed(texts: list[str]) -> list[list[float]]:\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-v4\",\n",
    "        input=texts,\n",
    "        dimensions=EMBED_DIM,\n",
    "    )\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "# Test if text embedding can be generated normally\n",
    "texts = [\n",
    "    \"LangGraph's middleware is very powerful\",\n",
    "    \"LangGraph's MCP is also very useful\",\n",
    "]\n",
    "vectors = embed(texts)\n",
    "\n",
    "len(vectors), len(vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf724b-0087-41fb-824b-4f7613618871",
   "metadata": {},
   "source": [
    "### 2.2 Reading and Writing Long-term Memory\n",
    "\n",
    "First, write two pieces of data into InMemoryStore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cd1e8f5-9d37-4c62-9060-f801912e1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create InMemoryStore memory storage\n",
    "store = InMemoryStore(index={\"embed\": embed, \"dims\": EMBED_DIM})\n",
    "\n",
    "# Add two user data records user_1 user_2\n",
    "namespace = (\"users\", )\n",
    "\n",
    "store.put(\n",
    "    namespace,  # Namespace to group related data together\n",
    "    \"user_1\",  # Key within the namespace\n",
    "    {\n",
    "        \"rules\": [\n",
    "            \"User likes short, direct language\",\n",
    "            \"User only speaks English & python\",\n",
    "        ],\n",
    "        \"rule_id\": \"3\",\n",
    "    },\n",
    ")\n",
    "\n",
    "store.put(\n",
    "    (\"users\",),\n",
    "    \"user_2\",\n",
    "    {\n",
    "        \"name\": \"John Smith\",\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48d0ee-0fcc-429a-b97a-1d770647f8b9",
   "metadata": {},
   "source": [
    "Through namespace and key, you can directly read long-term memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc685e6-9c90-44be-8357-9ef8cb3572e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item(namespace=['users'], key='user_2', value={'name': 'John Smith', 'language': 'English'}, created_at='2026-02-14T10:51:23.965935+00:00', updated_at='2026-02-14T10:51:23.965948+00:00')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = store.get(namespace, \"user_2\")\n",
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32de92b-5993-469f-a1ee-717772f632e8",
   "metadata": {},
   "source": [
    "You can also retrieve through vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d179606e-978d-4469-92ab-23bad25c391f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['users'], key='user_1', value={'rules': ['User likes short, direct language', 'User only speaks English & python'], 'rule_id': '3'}, created_at='2026-02-14T10:51:23.135391+00:00', updated_at='2026-02-14T10:51:23.135400+00:00', score=0.4085710154661828)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = store.search( \n",
    "    namespace,\n",
    "    query=\"language preferences\",\n",
    "    filter={\"rule_id\": \"3\"},\n",
    ")\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0908fd8e-e04b-41f6-ba2d-61449d219d81",
   "metadata": {},
   "source": [
    "### 2.3 Using Tools to Read Long-term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd5f5405-5e7f-4d01-a77d-f5c5e30e54d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Check user info\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_user_info (call_6d114bb7a56d476fb425db59)\n",
      " Call ID: call_6d114bb7a56d476fb425db59\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_user_info\n",
      "\n",
      "{'name': 'John Smith', 'language': 'English'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The user information is as follows:\n",
      "\n",
      "- **Name**: John Smith\n",
      "- **Language**: English\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_info(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Used to query user information\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    user_info = runtime.store.get((\"users\",), user_id) \n",
    "    return str(user_info.value) if user_info else \"Unknown user\"\n",
    "\n",
    "# Create Agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_info],\n",
    "    store=store, \n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# Run Agent\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Check user info\"}]},\n",
    "    context=Context(user_id=\"user_2\") \n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0d880-2ece-429a-b4c0-a93de51e70da",
   "metadata": {},
   "source": [
    "### 2.4 Using Tools to Write Long-term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23fce454-a575-412e-a31c-b196731e6539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Smith'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UserInfo(TypedDict):\n",
    "    name: str\n",
    "\n",
    "@tool\n",
    "def save_user_info(user_info: UserInfo, runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Used to save/update user information\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    runtime.store.put((\"users\",), user_id, user_info) \n",
    "    return \"Successfully saved user information\"\n",
    "\n",
    "# Create Agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[save_user_info],\n",
    "    store=store,\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# Run Agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is John Smith\"}]},\n",
    "    context=Context(user_id=\"user_123\") \n",
    ")\n",
    "\n",
    "store.get((\"users\",), \"user_123\").value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4bfc1-bec6-43ee-9f5d-0130f98b2ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3.13)",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
