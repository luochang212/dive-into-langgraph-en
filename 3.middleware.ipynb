{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da96a78-5bcd-4ea3-b5cc-addb660a1554",
   "metadata": {},
   "source": [
    "# Middleware\n",
    "\n",
    "[Middleware](https://docs.langchain.com/oss/python/langchain/middleware/overview) is the most impressive feature in this update. Many new features are implemented through middleware, such as Human-in-the-loop (HITL), dynamic system prompts, dynamic context injection, and more. Middleware is a hook function. By embedding middleware in workflows, efficient extension and customization of workflows can be achieved.\n",
    "\n",
    "LangChain creates **custom middleware** through [decorators](https://reference.langchain.com/python/langchain/middleware/#decorators).\n",
    "\n",
    "```{dropdown} Decorator Types (Click to Expand)\n",
    "\n",
    "  | DECORATOR | DESCRIPTION |\n",
    "  | -- | -- |\n",
    "  | `@before_agent` | Execute logic before Agent execution |\n",
    "  | `@after_agent` | Execute logic after Agent execution |\n",
    "  | `@before_model` | Execute logic before each model call |\n",
    "  | `@after_model` | Execute logic after each model receives a response |\n",
    "  | `@wrap_model_call` | Control the model's calling process |\n",
    "  | `@wrap_tool_call` | Control the tool's calling process |\n",
    "  | `@dynamic_prompt` | Dynamically generate system prompts |\n",
    "  | `@hook_config` | Configure hook behavior |\n",
    "\n",
    "```\n",
    "\n",
    "**Decorator Type** determines the execution position of the middleware. For example, using the `@before_model` decorator allows specific logic to be executed before the model call. The **decorated function** is responsible for the specific implementation of this logic. This might sound a bit abstract. Don't worry, this section provides four examples. After reading them, you will definitely understand how to use middleware:\n",
    "\n",
    "- Budget Control\n",
    "- Message Truncation\n",
    "- Sensitive Word Filtering\n",
    "- PII Detection (Personally Identifiable Information Detection)\n",
    "\n",
    "## 1. Budget Control\n",
    "\n",
    "As the number of conversation rounds increases, the conversation history becomes longer, leading to higher request costs. To control the budget, you can set up automatic switching to a lower-cost model when the conversation rounds exceed a certain threshold. Below we implement this feature using custom middleware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd14ba5-4b0c-4cfb-a976-040d0a365f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.messages import HumanMessage\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# Load model configuration\n",
    "_ = load_dotenv()\n",
    "\n",
    "# Low-cost model\n",
    "basic_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    ")\n",
    "\n",
    "# High-cost model\n",
    "advanced_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4033cbf-b59f-4a6b-9fd1-f102b7fea252",
   "metadata": {},
   "source": [
    "Since our modifications involve model inference, `@before_model` and `@after_model` are not sufficient here. We choose the [`@wrap_model_call`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.wrap_model_call) decorator that can interfere with model calls. The specific logic is implemented by the function `dynamic_model_selection`: when the conversation history exceeds 5 messages, automatically switch to the lower-cost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e758792-47d8-4ea4-857e-dddbbc71eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 5:\n",
    "        # Use a basic model for longer conversations\n",
    "        model = basic_model\n",
    "    else:\n",
    "        model = advanced_model\n",
    "\n",
    "    print(f\"message_count: {message_count}\")\n",
    "    print(f\"model_name: {model.model_name}\")\n",
    "\n",
    "    return handler(request.override(model=model))\n",
    "\n",
    "agent = create_agent(\n",
    "    model=advanced_model,  # Default model\n",
    "    middleware=[dynamic_model_selection]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850013a4",
   "metadata": {},
   "source": [
    "From the example below, we can see that when the message count `message_count` exceeds 5, it indeed switches from the high-cost model `qwen3-max` to the low-cost model `qwen3-coder-plus`. We have successfully implemented the budget control feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b4ed25-2ef8-4a24-9760-89f1ed34bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 ===\n",
      "message_count: 1\n",
      "model_name: qwen3-max\n",
      "content: A car typically has 4 wheels.\n",
      "\n",
      "=== Round 2 ===\n",
      "message_count: 3\n",
      "model_name: qwen3-max\n",
      "content: Most airplanes have 3 wheels (two main wheels and one nose wheel), but larger aircraft can have more.\n",
      "\n",
      "=== Round 3 ===\n",
      "message_count: 5\n",
      "model_name: qwen3-max\n",
      "content: A motorcycle has 2 wheels.\n",
      "\n",
      "=== Round 4 ===\n",
      "message_count: 7\n",
      "model_name: qwen3-coder-plus\n",
      "content: A bicycle has 2 wheels.\n"
     ]
    }
   ],
   "source": [
    "state: MessagesState = {\"messages\": []}\n",
    "items = ['car', 'airplane', 'motorcycle', 'bicycle']\n",
    "for idx, i in enumerate(items):\n",
    "    print(f\"\\n=== Round {idx+1} ===\")\n",
    "    state[\"messages\"] += [HumanMessage(content=f\"{i}How many wheels does it have? Answer briefly.\")]\n",
    "    result = agent.invoke(state)\n",
    "    state[\"messages\"] = result[\"messages\"]\n",
    "    print(f'content: {result[\"messages\"][-1].content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc58247-324d-40fe-83e5-b34f9ec564e6",
   "metadata": {},
   "source": [
    "## 2. Message Truncation\n",
    "\n",
    "LLMs have context length limits. Once exceeded, the context needs to be compressed. Among the many processing solutions, message truncation is the simplest. Below we implement message truncation functionality through the `@before_model` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08619c1-6940-4043-be1b-3282be16c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750eee1-a873-424c-878b-61ec5bf81f0e",
   "metadata": {},
   "source": [
    "We try a truncation strategy: while keeping recent messages, additionally keep the first message. In the example below, since we told the agent \"I am bob\" in the first message, it remembers that I am bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aefc09f4-d67f-4a7a-b930-171043e0a37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob! You told me \"hi, my name is bob\" at the beginning of our conversation.\n"
     ]
    }
   ],
   "source": [
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    basic_model,\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "def agent_invoke(agent):\n",
    "    agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "    agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "    agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "    final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "    \n",
    "    final_response[\"messages\"][-1].pretty_print()\n",
    "\n",
    "agent_invoke(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2afa04-18ad-487d-9cef-dfba0b5ec36d",
   "metadata": {},
   "source": [
    "Of course, this performance is not enough to prove that the truncation middleware really works. If this middleware never took effect, the result would be the same. To prove it really works, we modify the truncation strategy again. This time, only keep the last two conversation records. If the agent doesn't remember that I am bob, it means the truncation middleware is indeed working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc2a8e62-b7c4-4275-8967-7c551a73c6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have access to your personal information, so I don't know your name. This is because privacy is important, and I'm designed not to store or access any personal data about users.\n",
      "\n",
      "If you'd like to tell me your name, feel free to share it! But please remember that if you're using a shared device or account, you might want to be cautious about sharing personal information. \n",
      "\n",
      "Is there something specific I can help you with today?\n"
     ]
    }
   ],
   "source": [
    "@before_model\n",
    "def trim_without_first_message(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *messages[-2:]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    basic_model,\n",
    "    middleware=[trim_without_first_message],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "agent_invoke(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e989c",
   "metadata": {},
   "source": [
    "Now the agent doesn't remember who I am, which means the middleware is indeed working!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1220c4b-13f2-48e0-90d8-3fb2bc92e5bd",
   "metadata": {},
   "source": [
    "## 3. Sensitive Word Filtering\n",
    "\n",
    "**Guardrails** is a general term for content security capabilities provided by agents. Large models themselves have certain content risk control capabilities, but they are easily bypassed. Search for \"jailbreaking LLM\" to find such tutorials. Agents can provide additional security protection outside the model. This is achieved through engineering-based mandatory checks.\n",
    "\n",
    "In LangGraph, guardrails can be easily implemented through middleware. Below we implement a simple guardrail: if the user's latest message contains certain sensitive words, the agent will refuse to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c5cc5b-7b4a-4658-8f86-feb8114d04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain.agents.middleware import before_agent, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "banned_keywords = [\"hack\", \"exploit\", \"malware\"]\n",
    "\n",
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_filter(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "\n",
    "    # Check for banned keywords\n",
    "    for keyword in banned_keywords:\n",
    "        if keyword in content:\n",
    "            # Block execution before any processing\n",
    "            return {\n",
    "                \"messages\": [{\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n",
    "                }],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "\n",
    "    return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,\n",
    "    middleware=[content_filter],\n",
    ")\n",
    "\n",
    "# This request will be blocked before any processing\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I hack into a database?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55cad2e8-ab78-44d6-8682-1e0fe17469a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How do I hack into a database?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I cannot process requests containing inappropriate content. Please rephrase your request.\n"
     ]
    }
   ],
   "source": [
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761479b-d432-4e09-9341-4b5ad8363b48",
   "metadata": {},
   "source": [
    "## 4. PII Detection\n",
    "\n",
    "Next, we continue to write guardrails. [PII](https://docs.langchain.com/oss/python/langchain/guardrails#pii-detection) (Personally Identifiable Information) detection can discover personal privacy information such as emails, IPs, addresses, and bank cards in user input and take appropriate action.\n",
    "\n",
    "The following example comes from real life. We often copy error messages to LLMs to help debug. But error messages may contain personal privacy information. For this situation, we use the following two methods to handle it:\n",
    "\n",
    "1. Refuse to answer the question\n",
    "2. Mask the privacy information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0697a36-a7f6-46dc-acf0-44eed2c56daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Trusted model, usually a local model; for convenience, we still use qwen here\n",
    "trusted_model = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    ")\n",
    "\n",
    "# Used to format agent output; returns True if sensitive info is found, False otherwise\n",
    "class PiiCheck(BaseModel):\n",
    "    \"\"\"Structured output indicating whether text contains PII.\"\"\"\n",
    "    is_pii: bool = Field(description=\"Whether the text contains PII\")\n",
    "\n",
    "def message_with_pii(pii_middleware):\n",
    "    agent = create_agent(\n",
    "        model=basic_model,\n",
    "        middleware=[pii_middleware],\n",
    "    )\n",
    "\n",
    "    # This request will be blocked before any processing\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": dedent(\n",
    "                \"\"\"\n",
    "                File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
    "                    agent = create_react_agent(\n",
    "                ---\n",
    "                Where is the error location?\n",
    "                \"\"\").strip()\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b344fe-5bb5-4349-9183-ed163b5fde4a",
   "metadata": {},
   "source": [
    "**Handling Method 1**: If privacy information is detected, refuse to respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6400b371-034f-4c71-8dd6-6c5f115a0b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_blocker(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "    prompt = (\n",
    "        \"You are a privacy protection assistant. Please identify personally identifiable information (PII) in the following text, \"\n",
    "        \"such as: name, ID number, passport number, phone number, email, address, bank card number, social media account, license plate, etc. \"\n",
    "        \"Note that if code or file paths contain usernames, they should also be considered sensitive information. \"\n",
    "        \"If sensitive information is found, return {\\\"is_pii\\\": True}, otherwise return {\\\"is_pii\\\": False}. \"\n",
    "        \"Please strictly return in JSON format and only output the JSON. The text is:\\n\\n\" + content\n",
    "    )\n",
    "\n",
    "    pii_agent = trusted_model.with_structured_output(PiiCheck)\n",
    "    result = pii_agent.invoke(prompt)\n",
    "\n",
    "    if result.is_pii is True:\n",
    "        # Block execution before any processing\n",
    "        return {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"I cannot process requests containing inappropriate content. Please rephrase your request.\"\n",
    "            }],\n",
    "            \"jump_to\": \"end\"\n",
    "        }\n",
    "    else:\n",
    "        print(\"No PII found\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ba27fa-cb71-4dd2-b051-7ef949d1cfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "---\n",
      "Where is the error location?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I cannot process requests containing inappropriate content. Please rephrase your request.\n"
     ]
    }
   ],
   "source": [
    "result = message_with_pii(pii_middleware=content_blocker)\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e9ad2b-18f9-41e1-995b-81572753f4d2",
   "metadata": {},
   "source": [
    "**Handling Method 2**: If sensitive information is detected, use a series of `*****` to mask the privacy information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7a946d8-fde3-4348-82e4-3801481a332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_agent(can_jump_to=[\"end\"])\n",
    "def content_filter(state: AgentState,  runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "    # Get the first user message\n",
    "    if not state[\"messages\"]:\n",
    "        return None\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.type != \"human\":\n",
    "        return None\n",
    "\n",
    "    content = last_message.content.lower()\n",
    "    prompt = (\n",
    "        \"You are a privacy protection assistant. Please identify personally identifiable information (PII) in the following text, \"\n",
    "        \"such as: name, ID number, passport number, phone number, email, address, bank card number, social media account, license plate, etc. \"\n",
    "        \"Note that if code or file paths contain usernames, they should also be considered sensitive information. \"\n",
    "        \"If sensitive information is found, return {\\\"is_pii\\\": True}, otherwise return {\\\"is_pii\\\": False}. \"\n",
    "        \"Please strictly return in JSON format and only output the JSON. The text is:\\n\\n\" + content\n",
    "    )\n",
    "\n",
    "    pii_agent = trusted_model.with_structured_output(PiiCheck)\n",
    "    result = pii_agent.invoke(prompt)\n",
    "\n",
    "    if result.is_pii is True:\n",
    "        mask_prompt = (\n",
    "            \"You are a privacy protection assistant. Please replace all personally identifiable information (PII) in the following text with asterisks (*). \"\n",
    "            \"Only replace sensitive fragments, keep other text unchanged. \"\n",
    "            \"Only output the processed text, no explanations or additional content. The text is:\\n\\n\" + last_message.content\n",
    "        )\n",
    "        masked_message = basic_model.invoke(mask_prompt)\n",
    "        return {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": masked_message.content\n",
    "            }]\n",
    "        }\n",
    "    else:\n",
    "        print(\"No PII found\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2480e24d-39b9-4329-a008-6b162850f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "File \"/home/luochang/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "---\n",
      "Where is the error location?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "File \"/home/******/proj/agent.py\", line 53, in my_agent\n",
      "    agent = create_react_agent(\n",
      "---\n",
      "Where is the error location?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The error is occurring at **line 53** in the file `/home/luochang/proj/agent.py`, specifically within the `my_agent` function where the `create_react_agent()` function is being called.\n",
      "\n",
      "However, the traceback you've shown only shows the beginning of the error - it's incomplete. To see the exact error message and understand what's going wrong, you need to look at the rest of the traceback that comes after this line.\n",
      "\n",
      "The complete error traceback would typically show:\n",
      "- The specific error type (like `TypeError`, `ValueError`, `ImportError`, etc.)\n",
      "- The detailed error message\n",
      "- The full stack trace showing all function calls leading to the error\n",
      "\n",
      "To get the complete error information, you should:\n",
      "\n",
      "1. **Check the full console output** - the actual error message should be below what you've shown\n",
      "2. **Look for the error type and message** - it will tell you exactly what went wrong\n",
      "3. **Common issues with `create_react_agent`** might include:\n",
      "   - Missing required parameters\n",
      "   - Incorrect parameter types\n",
      "   - Import issues\n",
      "   - Missing dependencies\n",
      "\n",
      "Could you share the complete error message? That would help identify the exact problem at line 53.\n"
     ]
    }
   ],
   "source": [
    "result = message_with_pii(pii_middleware=content_filter)\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d7771-f9b8-4408-9387-c67c51c1a155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
