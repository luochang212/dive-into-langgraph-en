{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6455fef-d8c7-4671-88b8-38bc29d480cd",
   "metadata": {},
   "source": [
    "# Human-in-the-Loop\n",
    "\n",
    "[Human-in-the-loop](https://docs.langchain.com/oss/python/langchain/human-in-the-loop) (HITL) refers to the process where an Agent actively interrupts to request execution permission or additional information from humans, and continues execution after receiving human feedback.\n",
    "\n",
    "LangGraph's HITL functionality can be implemented through the built-in middleware `HumanInTheLoopMiddleware` (HITL). After triggering HITL, the middleware saves the current state to a [checkpointer](https://docs.langchain.com/oss/javascript/langgraph/persistence#checkpointer-libraries) checkpoint and waits for human response. After receiving the response, it restores the state from the checkpoint and continues task execution.\n",
    "\n",
    "> **Note**\n",
    "> This example only demonstrates the role of checkpoint in HITL. It doesn't matter whether the memory persists after the thread ends, so we use in-memory storage `InMemorySaver`. In production environments, please use persistent checkpoints such as:\n",
    ">\n",
    "> - `SqliteSaver`\n",
    "> - `PostgresSaver`\n",
    "> - `MongoDBSaver`\n",
    "> - `RedisSaver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7964beb-09a7-491d-bc62-3dc2a6317981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langchain.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Load model configuration\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e27a63",
   "metadata": {},
   "source": [
    "Below we use the HITL middleware to configure manual approval workflows for three tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee418c5-8864-40d6-9ff7-c918d410ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LLM service\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    ")\n",
    "\n",
    "# Tool functions\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@tool\n",
    "def add_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and return the sum.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def calculate_bmi(weight_kg: float, height_m: float) -> float:\n",
    "    \"\"\"Calculate BMI given weight in kg and height in meters.\"\"\"\n",
    "    if height_m <= 0 or weight_kg <= 0:\n",
    "        raise ValueError(\"height_m and weight_kg must be greater than 0.\")\n",
    "    return weight_kg / (height_m ** 2)\n",
    "\n",
    "# Create Agent with tool calling\n",
    "tool_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather, add_numbers, calculate_bmi],\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware( \n",
    "            interrupt_on={\n",
    "                # No need to trigger human approval\n",
    "                \"get_weather\": False,\n",
    "                # Requires approval, allows approve, edit, reject decision types\n",
    "                \"add_numbers\": True,\n",
    "                # Requires approval, allows approve, reject decision types\n",
    "                \"calculate_bmi\": {\"allowed_decisions\": [\"approve\", \"reject\"]},\n",
    "            },\n",
    "            description_prefix=\"Tool execution pending approval\",\n",
    "        ),\n",
    "    ],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b35941-f9ca-4bdb-b58f-4e0a7fbb52ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Interrupt(value={'action_requests': [{'name': 'calculate_bmi', 'args': {'height_m': 1.8, 'weight_kg': 90}, 'description': \"Tool execution pending approval\\n\\nTool: calculate_bmi\\nArgs: {'height_m': 1.8, 'weight_kg': 90}\"}], 'review_configs': [{'action_name': 'calculate_bmi', 'allowed_decisions': ['approve', 'reject']}]}, id='9f0da0ba54cd2526d9ca530ba6fc27f2')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Agent\n",
    "config = {'configurable': {'thread_id': str(uuid.uuid4())}}\n",
    "result = tool_agent.invoke(\n",
    "    {\"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I am 180cm tall and weigh 90kg, what is my BMI?\"\n",
    "        # \"content\": \"what is the weather in sf\"\n",
    "    }]},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# result['messages'][-1].content\n",
    "result.get('__interrupt__')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1560dd",
   "metadata": {},
   "source": [
    "From the interrupt information, we can see that the Agent has triggered the `calculate_bmi` tool call and entered a waiting-for-approval state. Below we send an \"approval\" command to the Agent to resume its execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f50ef1a9-f11e-4f81-bdd6-6c3dfd6aa056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your BMI is approximately 27.78, which is considered overweight.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resume with approval decision\n",
    "result = tool_agent.invoke(\n",
    "    Command(\n",
    "        resume={\"decisions\": [{\"type\": \"approve\"}]}  # or \"edit\", \"reject\"\n",
    "    ), \n",
    "    config=config\n",
    ")\n",
    "\n",
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d9b73d-80c2-4041-94d7-e093a529dcaa",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> In addition to HITL, LangChain provides various **built-in middleware**. Here are just a few examples; the complete list can be found in the [API documentation](https://reference.langchain.com/python/langchain/middleware/#middleware-classes).\n",
    "> \n",
    "> | CLASS | DESCRIPTION |\n",
    "> | --- | --- |\n",
    "> | SummarizationMiddleware | Automatically summarizes conversation history when approaching token limits |\n",
    "> | ModelCallLimitMiddleware | Limits model call frequency to prevent excessive costs |\n",
    "> | ToolCallLimitMiddleware | Controls tool execution by limiting call frequency |\n",
    "> | ModelFallbackMiddleware | Automatically falls back to backup model when primary model fails |\n",
    "> | ... | ... |\n",
    "\n",
    "Reference documentation:\n",
    "\n",
    "- [langchain/human-in-the-loop](https://docs.langchain.com/oss/python/langchain/human-in-the-loop)\n",
    "- [langchain/short-term-memory](https://docs.langchain.com/oss/python/langchain/short-term-memory)\n",
    "- [langchain/long-term-memory](https://docs.langchain.com/oss/python/langchain/long-term-memory)\n",
    "- [langgraph/persistence](https://docs.langchain.com/oss/python/langgraph/persistence)\n",
    "- [langgraph/use-time-travel](https://docs.langchain.com/oss/python/langgraph/use-time-travel)\n",
    "- [langgraph/add-memory](https://docs.langchain.com/oss/python/langgraph/add-memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34866a-78fe-4c20-b78c-72a1d79b4fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
